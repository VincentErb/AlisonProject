{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"App/","text":"The Alison Project Android Application The android application for the state-of-the-art sound recognition solution designed to help people suffering from hearing impairement or deafness all over the world. More details on our website Getting Started You can dowload the android application on our website or directly from this git repository. The application be soon available on the Google PlayStore. Usage In the first screen of the application you have to find the raspberry device to which you want to connect Then clik connect After that you can start recoding the sound you want to recognize by clicking the start record icon When you finish you can click it again to stop recording then enter a tag to assciate to the record and select light color to emit when the device recognize the sound. Finally you can click Ok to validate. yeay!\ud83e\udd17 your sound is learned Prerequisites A phone device running android version >= 4.16 and supporting bluetooth. A Raspberry pi configure following steps defined on this repository and here Android [JellyBean](https://developer.android.com/reference/android/os/Build.VERSION_CODES.html#JELLY_BEAN) Installing Android studio: dowload here . clone this repository and open it in android studio Built With Android_studio - The development kit. Contributing Please read CONTRIBUTING.md for details on our code of conduct, and the process for submitting pull requests to us. Versioning For the versions available, see the tags on this repository . Authors Alison Project Team - Initial work website See also the list of contributors who participated in this project. License This project is licensed under the GPL3 License - see the LICENSE.md file on Github for details Acknowledgments @pes8 - Android color picker INSA Toulouse","title":"The Alison Project Android Application"},{"location":"App/#the-alison-project-android-application","text":"The android application for the state-of-the-art sound recognition solution designed to help people suffering from hearing impairement or deafness all over the world. More details on our website","title":"The Alison Project Android Application"},{"location":"App/#getting-started","text":"You can dowload the android application on our website or directly from this git repository. The application be soon available on the Google PlayStore.","title":"Getting Started"},{"location":"App/#usage","text":"In the first screen of the application you have to find the raspberry device to which you want to connect Then clik connect After that you can start recoding the sound you want to recognize by clicking the start record icon When you finish you can click it again to stop recording then enter a tag to assciate to the record and select light color to emit when the device recognize the sound. Finally you can click Ok to validate. yeay!\ud83e\udd17 your sound is learned","title":"Usage"},{"location":"App/#prerequisites","text":"A phone device running android version >= 4.16 and supporting bluetooth. A Raspberry pi configure following steps defined on this repository and here Android [JellyBean](https://developer.android.com/reference/android/os/Build.VERSION_CODES.html#JELLY_BEAN)","title":"Prerequisites"},{"location":"App/#installing","text":"Android studio: dowload here . clone this repository and open it in android studio","title":"Installing"},{"location":"App/#built-with","text":"Android_studio - The development kit.","title":"Built With"},{"location":"App/#contributing","text":"Please read CONTRIBUTING.md for details on our code of conduct, and the process for submitting pull requests to us.","title":"Contributing"},{"location":"App/#versioning","text":"For the versions available, see the tags on this repository .","title":"Versioning"},{"location":"App/#authors","text":"Alison Project Team - Initial work website See also the list of contributors who participated in this project.","title":"Authors"},{"location":"App/#license","text":"This project is licensed under the GPL3 License - see the LICENSE.md file on Github for details","title":"License"},{"location":"App/#acknowledgments","text":"@pes8 - Android color picker INSA Toulouse","title":"Acknowledgments"},{"location":"GetStarted/","text":"Get Started Hardware requirements The Alison System requires three main hardware components to function : An android phone with Android version 5.0 Lollipop or later A Philips Hue system with multi-color lightbulb (both lightbulb AND bridge) A Raspberry Pi 3B+ (other versions may be functional but have not yet been tested) Raspberry Pi Software Installation Prerequisites Your Raspberry Pi must run the latest version of Raspbian available. More info about Raspbian here Installing the Respeaker 4-Mic Get the seeed voice card source code sudo apt-get update sudo apt-get upgrade git clone https://github.com/respeaker/seeed-voicecard.git cd seeed-voicecard sudo ./install.sh sudo reboot Select the headphone jack on Raspberry Pi for audio output sudo raspi-config Select 7 Advanced Options Select A4 Audio Select 1 Force 3.5mm ('headphone') jack Select Finish Install the respeaker library sudo apt install python3-pip pip install pocketsphinx webrtcvad pip install pyaudio respeaker --upgrade pip install -U https://github.com/respeaker/respeaker_python_library/archive/master.zip Packages to install sudo pip install numpy scipy matplotlib soundfile resampy audioread phue netifaces sudo apt-get install python-tk Setup DHCP on Ethernet port to connecte with Philips Hue bridge Assign a static IP address to the Ethernet port (eth0) sudo nano /etc/dhcpcd.conf Uncomment the following lines at the bottom of the document: interface eth0 static ip_address=192.168.4.100/24 static domain_name_servers= .... Then reboot the Raspberry Pi using: sudo reboot Check that the IP address of eth0 has been changed to 198.162.4.100 using: ifconfig eth0|grep \u2018inet \u2018 Install the DHCP daemon (isc-dhcp-server) sudo apt-get update sudo apt-get install isc-dhcp-server sudo nano /etc/dhcp/dhcpd.conf At the bottom of the file that opens, write the following lines: option subnet-mask 255.255.255.0; option routers 192.168.4.100; subnet 192.168.4.0 netmask 255.255.255.0 { range 192.168.4.50 192.168.4.99; } Then : sudo nano /etc/defaults/isc-dhcp-server In the file that opens, uncomment the following lines and add eth0 on the last one: DHCPD_CONF=/etc/dhcp/dhcpd.conf DHCPD_PID=/var/run/dhcpd.pid INTERFACES=\"eth0\" Companion App installation Requirements The app requires an Android device version 5.0 (Lollipop) or higher with a functioning bluetooth connectivity. Installation The app isn't available on the Google Play Store yet. Simply download the apk from our website and that's it ! You're now ready to use the Alison System ! Using the app to record sounds With the Raspberry Pi set-up and connected, get into the companion app and start recording sounds that you want to recognize, and associating a color with each sound. The system is now fully operational ! It will detect sounds in real time, and you can add or remove a given sound any time using the app.","title":"Get Started"},{"location":"GetStarted/#get-started","text":"","title":"Get Started"},{"location":"GetStarted/#hardware-requirements","text":"The Alison System requires three main hardware components to function : An android phone with Android version 5.0 Lollipop or later A Philips Hue system with multi-color lightbulb (both lightbulb AND bridge) A Raspberry Pi 3B+ (other versions may be functional but have not yet been tested)","title":"Hardware requirements"},{"location":"GetStarted/#raspberry-pi-software-installation","text":"","title":"Raspberry Pi Software Installation"},{"location":"GetStarted/#prerequisites","text":"Your Raspberry Pi must run the latest version of Raspbian available. More info about Raspbian here","title":"Prerequisites"},{"location":"GetStarted/#installing-the-respeaker-4-mic","text":"Get the seeed voice card source code sudo apt-get update sudo apt-get upgrade git clone https://github.com/respeaker/seeed-voicecard.git cd seeed-voicecard sudo ./install.sh sudo reboot Select the headphone jack on Raspberry Pi for audio output sudo raspi-config Select 7 Advanced Options Select A4 Audio Select 1 Force 3.5mm ('headphone') jack Select Finish Install the respeaker library sudo apt install python3-pip pip install pocketsphinx webrtcvad pip install pyaudio respeaker --upgrade pip install -U https://github.com/respeaker/respeaker_python_library/archive/master.zip","title":"Installing the Respeaker 4-Mic"},{"location":"GetStarted/#packages-to-install","text":"sudo pip install numpy scipy matplotlib soundfile resampy audioread phue netifaces sudo apt-get install python-tk","title":"Packages to install"},{"location":"GetStarted/#setup-dhcp-on-ethernet-port-to-connecte-with-philips-hue-bridge","text":"Assign a static IP address to the Ethernet port (eth0) sudo nano /etc/dhcpcd.conf Uncomment the following lines at the bottom of the document: interface eth0 static ip_address=192.168.4.100/24 static domain_name_servers= .... Then reboot the Raspberry Pi using: sudo reboot Check that the IP address of eth0 has been changed to 198.162.4.100 using: ifconfig eth0|grep \u2018inet \u2018","title":"Setup DHCP on Ethernet port to connecte with Philips Hue bridge"},{"location":"GetStarted/#install-the-dhcp-daemon-isc-dhcp-server","text":"sudo apt-get update sudo apt-get install isc-dhcp-server sudo nano /etc/dhcp/dhcpd.conf At the bottom of the file that opens, write the following lines: option subnet-mask 255.255.255.0; option routers 192.168.4.100; subnet 192.168.4.0 netmask 255.255.255.0 { range 192.168.4.50 192.168.4.99; } Then : sudo nano /etc/defaults/isc-dhcp-server In the file that opens, uncomment the following lines and add eth0 on the last one: DHCPD_CONF=/etc/dhcp/dhcpd.conf DHCPD_PID=/var/run/dhcpd.pid INTERFACES=\"eth0\"","title":"Install the DHCP daemon (isc-dhcp-server)"},{"location":"GetStarted/#companion-app-installation","text":"","title":"Companion App installation"},{"location":"GetStarted/#requirements","text":"The app requires an Android device version 5.0 (Lollipop) or higher with a functioning bluetooth connectivity.","title":"Requirements"},{"location":"GetStarted/#installation","text":"The app isn't available on the Google Play Store yet. Simply download the apk from our website and that's it ! You're now ready to use the Alison System !","title":"Installation"},{"location":"GetStarted/#using-the-app-to-record-sounds","text":"With the Raspberry Pi set-up and connected, get into the companion app and start recording sounds that you want to recognize, and associating a color with each sound. The system is now fully operational ! It will detect sounds in real time, and you can add or remove a given sound any time using the app.","title":"Using the app to record sounds"},{"location":"Learning/","text":"Registering new sounds Any sound to be recognized by the system has to be recorded 4-5 times. The test samples are then treated to be used as dictionnary in the detection process. The following section refers to the python module : learning.py Audio file treatement We are using the Respeaker microphone to record a .WAV file from an input sound. The length of the recording is determined automatically by the Respeaker which stops recording when it detects the sound has stopped. Manual sound recording can be achieved using Respeaker's record function. Feature extraction NMF only requires the Fourier Transform of a sound to detect it, so the feature extraction process is rather simple. We load the .WAV file using Librosa*, and then compute the STFT (Short Term Fourier Transform) on the entire audio signal. This returns a 2D numpy array and the spectrogram obtained can be displayed in the learning module. def get_stft_from_file(wav): y, sample_rate = librosa.load(wav) return get_stft(y) def get_stft(data): # Window size : 1024 -> around 47 ms, rather standard for FFT m = np.abs(librosa.stft(data, n_fft=1024, window='hann')) return m We used a standard Fourier Transform sampling rate, and a hanning window with overlapping to maintain information integrity. The matrix is then given to NMF to be used in the dictionnary matrix.","title":"Registering new sounds"},{"location":"Learning/#registering-new-sounds","text":"Any sound to be recognized by the system has to be recorded 4-5 times. The test samples are then treated to be used as dictionnary in the detection process. The following section refers to the python module : learning.py","title":"Registering new sounds"},{"location":"Learning/#audio-file-treatement","text":"We are using the Respeaker microphone to record a .WAV file from an input sound. The length of the recording is determined automatically by the Respeaker which stops recording when it detects the sound has stopped. Manual sound recording can be achieved using Respeaker's record function.","title":"Audio file treatement"},{"location":"Learning/#feature-extraction","text":"NMF only requires the Fourier Transform of a sound to detect it, so the feature extraction process is rather simple. We load the .WAV file using Librosa*, and then compute the STFT (Short Term Fourier Transform) on the entire audio signal. This returns a 2D numpy array and the spectrogram obtained can be displayed in the learning module. def get_stft_from_file(wav): y, sample_rate = librosa.load(wav) return get_stft(y) def get_stft(data): # Window size : 1024 -> around 47 ms, rather standard for FFT m = np.abs(librosa.stft(data, n_fft=1024, window='hann')) return m We used a standard Fourier Transform sampling rate, and a hanning window with overlapping to maintain information integrity. The matrix is then given to NMF to be used in the dictionnary matrix.","title":"Feature extraction"},{"location":"Libraries/","text":"Resources and Libraries This project uses libraries to help with sound processing and signal analysis, mostly for NMF (Non-Negative-Matrix-Factorization). Respeaker The Respeaker Project is a sound processing peripheral for Raspberry Pi. Hardware-wise, it comprises 4 microphones allowing for sound source localization. Software-wise, it helps with sound encoding and processing (it also provides advanced features like speech recognition that are not used in this project). Learn more about the Respeaker Project We used the Respeaker to record .WAV files for new sound registering, and real time audio recording for the recognition process. LibROSA Our main library is LibROSA. It is a well known python signal processing tool that builds on sci-kit learn, another famous library. It helps us with everything from STFT's to our main recognizing tool : NMF. More about LibROSA Raspberry Pi problems While we installed every other library easily on our Raspberry Pi, dozens of hours of trial weren't enough for us to manage to insall LibROSA. LibROSA simply isn't meant for a Raspberry Pi processor. Fortunately, the methods used by Alison aren't the problematic ones in LibROSA. To solve the issue, we compiled our own mini version of LibROSA (the library is under ISC license, open to modifications) using only needed modules. PHue Phue is a library designed to control Philips Hue lights through python. It is used to communicate sound class detection information in real time. Get PHue Mkdocs Documentation for the project, including this page, was generated thanks to Mkdocs, a static site generator from markdown. Custom theming has also been applied using mkdocs-material. Learn more about Mkdocs Learn more about Mkdocs-material","title":"Resources and Libraries"},{"location":"Libraries/#resources-and-libraries","text":"This project uses libraries to help with sound processing and signal analysis, mostly for NMF (Non-Negative-Matrix-Factorization).","title":"Resources and Libraries"},{"location":"Libraries/#respeaker","text":"The Respeaker Project is a sound processing peripheral for Raspberry Pi. Hardware-wise, it comprises 4 microphones allowing for sound source localization. Software-wise, it helps with sound encoding and processing (it also provides advanced features like speech recognition that are not used in this project). Learn more about the Respeaker Project We used the Respeaker to record .WAV files for new sound registering, and real time audio recording for the recognition process.","title":"Respeaker"},{"location":"Libraries/#librosa","text":"Our main library is LibROSA. It is a well known python signal processing tool that builds on sci-kit learn, another famous library. It helps us with everything from STFT's to our main recognizing tool : NMF. More about LibROSA","title":"LibROSA"},{"location":"Libraries/#raspberry-pi-problems","text":"While we installed every other library easily on our Raspberry Pi, dozens of hours of trial weren't enough for us to manage to insall LibROSA. LibROSA simply isn't meant for a Raspberry Pi processor. Fortunately, the methods used by Alison aren't the problematic ones in LibROSA. To solve the issue, we compiled our own mini version of LibROSA (the library is under ISC license, open to modifications) using only needed modules.","title":"Raspberry Pi problems"},{"location":"Libraries/#phue","text":"Phue is a library designed to control Philips Hue lights through python. It is used to communicate sound class detection information in real time. Get PHue","title":"PHue"},{"location":"Libraries/#mkdocs","text":"Documentation for the project, including this page, was generated thanks to Mkdocs, a static site generator from markdown. Custom theming has also been applied using mkdocs-material. Learn more about Mkdocs Learn more about Mkdocs-material","title":"Mkdocs"},{"location":"NoticeNMF/","text":"Non-Negative Matrix Factorization Process In order to recognize a known sound from the audio input we use the Non-Negative Matrix Factorization (NMF) algorithm. This algorithm decomposes the matrix given by the STFT in two matrices : the dictionnary and the activation matrix. We make a dictionnary for each sound we want to recognize. We create the dictionnaries by computing NMF on the STFT of the concatenation of the sample of one sound. When there is an audio input we run NMF once for each dictionnary (e.q each sound), if the coefficients in the activation's matrix are superior to a limit during a certain amount of time we consider that the sound corresponding to the dictionnary is recognized. A signal is then send to the Philips Hue to light it up in the pre-defined color. Diagram of the NMF method in the system process Testing [] In order to test our programm we made a dictionnary for each sound from five samples of this sound. After we try to decompose complex sounds with the different dictionnaries. Each decomposition tell us if and when the sound is recognized. We tested our algorithms with several sounds playing at the same time, recording of sounds with noises and recording without sounds to recognized. Properties For the moment our algorithms manage to recognize sounds in a superoposition of sounds or in a noisy environnement. We can also recognized cut-up sounds (when there is only a part of the sound we want to recognise). We have some issues with false positive, meaning that we recognized sounds (especially doorbells) in a recording without sounds to recognize.","title":"Non-Negative Matrix Factorization"},{"location":"NoticeNMF/#non-negative-matrix-factorization","text":"","title":"Non-Negative Matrix Factorization"},{"location":"NoticeNMF/#process","text":"In order to recognize a known sound from the audio input we use the Non-Negative Matrix Factorization (NMF) algorithm. This algorithm decomposes the matrix given by the STFT in two matrices : the dictionnary and the activation matrix. We make a dictionnary for each sound we want to recognize. We create the dictionnaries by computing NMF on the STFT of the concatenation of the sample of one sound. When there is an audio input we run NMF once for each dictionnary (e.q each sound), if the coefficients in the activation's matrix are superior to a limit during a certain amount of time we consider that the sound corresponding to the dictionnary is recognized. A signal is then send to the Philips Hue to light it up in the pre-defined color.","title":"Process"},{"location":"NoticeNMF/#diagram-of-the-nmf-method-in-the-system-process","text":"","title":"Diagram of the NMF method in the system process"},{"location":"NoticeNMF/#testing","text":"[] In order to test our programm we made a dictionnary for each sound from five samples of this sound. After we try to decompose complex sounds with the different dictionnaries. Each decomposition tell us if and when the sound is recognized. We tested our algorithms with several sounds playing at the same time, recording of sounds with noises and recording without sounds to recognized.","title":"Testing"},{"location":"NoticeNMF/#properties","text":"For the moment our algorithms manage to recognize sounds in a superoposition of sounds or in a noisy environnement. We can also recognized cut-up sounds (when there is only a part of the sound we want to recognise). We have some issues with false positive, meaning that we recognized sounds (especially doorbells) in a recording without sounds to recognize.","title":"Properties"}]}